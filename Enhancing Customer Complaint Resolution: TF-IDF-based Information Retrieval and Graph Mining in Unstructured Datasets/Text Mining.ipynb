{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3094ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b1e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Complaints dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34fd2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFER_NAME</th>\n",
       "      <th>CUSTOMER_TYPE</th>\n",
       "      <th>COMPLAINT_TYPE</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>CASE_LEVEL_1</th>\n",
       "      <th>CASE_LEVEL_2</th>\n",
       "      <th>CASE_LEVEL_3</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>CURRENT_STATUS</th>\n",
       "      <th>ESCALATION_FLAG</th>\n",
       "      <th>...</th>\n",
       "      <th>CLOSE_GROUP</th>\n",
       "      <th>AGE_BRACKET</th>\n",
       "      <th>ACTUAL_COMPLAINT</th>\n",
       "      <th>CALLBACK_MECHANISM</th>\n",
       "      <th>RESOLUTION</th>\n",
       "      <th>RESOLUTION_DESCRIPTION</th>\n",
       "      <th>CASE_DESC</th>\n",
       "      <th>OPEN_GR</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FTTH Home</td>\n",
       "      <td>CBU</td>\n",
       "      <td>Technical</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Technical complaint</td>\n",
       "      <td>TC_INTERNET_CONFIGURATION</td>\n",
       "      <td>SNW-FTTH - WAN configuration / Tools</td>\n",
       "      <td>FTTH Home</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>User Not Filled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>إعادة برمجة من النظامby Sultan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CBU</td>\n",
       "      <td>Technical</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Technical complaint</td>\n",
       "      <td>TC_INTERNET_CONNEXION</td>\n",
       "      <td>4G - Frequent Disconnection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobile_BO</td>\n",
       "      <td>1</td>\n",
       "      <td>Actual Complaint</td>\n",
       "      <td>SMS</td>\n",
       "      <td>Coverage script was sent to the customer</td>\n",
       "      <td>The customer should pay TF + all due amounts i...</td>\n",
       "      <td>عدم التصفح وسوء الخدمه والرجاء اتخاذ قرار ...</td>\n",
       "      <td>System Administrator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super 4G on the go 100GB new</td>\n",
       "      <td>CBU</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Commercial claim</td>\n",
       "      <td>CC_Offers</td>\n",
       "      <td>Embedded Bundle - Didn't Get The Monthly Bundles</td>\n",
       "      <td>Family Mobile-IEW</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobile_BO</td>\n",
       "      <td>1</td>\n",
       "      <td>Actual Complaint</td>\n",
       "      <td>SMS</td>\n",
       "      <td>IEW offer -no link</td>\n",
       "      <td>the line is active now &amp; linked &amp; getting the ...</td>\n",
       "      <td>Activation date Sep 22 2022  لم يتم اضافة ا...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro Bitstream</td>\n",
       "      <td>CBU</td>\n",
       "      <td>Technical</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Technical complaint</td>\n",
       "      <td>TC_Network</td>\n",
       "      <td>SNW-ADSL-Individual fault</td>\n",
       "      <td>Internet SME</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>User Not Filled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FTTH Home</td>\n",
       "      <td>CBU</td>\n",
       "      <td>Technical</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Technical complaint</td>\n",
       "      <td>TC_Network</td>\n",
       "      <td>SNW-FTTH - Down interrupted</td>\n",
       "      <td>FTTH Home</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>User Not Filled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interrupted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OFFER_NAME CUSTOMER_TYPE COMPLAINT_TYPE   PRODUCT  \\\n",
       "0                     FTTH Home           CBU      Technical  Internet   \n",
       "1                           NaN           CBU      Technical    Mobile   \n",
       "2  Super 4G on the go 100GB new           CBU     Commercial    Mobile   \n",
       "3                 Pro Bitstream           CBU      Technical  Internet   \n",
       "4                     FTTH Home           CBU      Technical  Internet   \n",
       "\n",
       "          CASE_LEVEL_1               CASE_LEVEL_2  \\\n",
       "0  Technical complaint  TC_INTERNET_CONFIGURATION   \n",
       "1  Technical complaint      TC_INTERNET_CONNEXION   \n",
       "2     Commercial claim                  CC_Offers   \n",
       "3  Technical complaint                 TC_Network   \n",
       "4  Technical complaint                 TC_Network   \n",
       "\n",
       "                                       CASE_LEVEL_3     CUSTOMER_GROUP  \\\n",
       "0              SNW-FTTH - WAN configuration / Tools          FTTH Home   \n",
       "1                       4G - Frequent Disconnection                NaN   \n",
       "2  Embedded Bundle - Didn't Get The Monthly Bundles  Family Mobile-IEW   \n",
       "3                         SNW-ADSL-Individual fault       Internet SME   \n",
       "4                       SNW-FTTH - Down interrupted          FTTH Home   \n",
       "\n",
       "  CURRENT_STATUS ESCALATION_FLAG  ... CLOSE_GROUP AGE_BRACKET  \\\n",
       "0       Resolved              No  ...         NaN           1   \n",
       "1       Resolved             Yes  ...   Mobile_BO           1   \n",
       "2       Resolved             Yes  ...   Mobile_BO           1   \n",
       "3       Resolved              No  ...         NaN           1   \n",
       "4       Resolved              No  ...         NaN           1   \n",
       "\n",
       "   ACTUAL_COMPLAINT CALLBACK_MECHANISM  \\\n",
       "0   User Not Filled                NaN   \n",
       "1  Actual Complaint                SMS   \n",
       "2  Actual Complaint                SMS   \n",
       "3   User Not Filled                NaN   \n",
       "4   User Not Filled                NaN   \n",
       "\n",
       "                                 RESOLUTION  \\\n",
       "0                                       NaN   \n",
       "1  Coverage script was sent to the customer   \n",
       "2                       IEW offer -no link    \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "                              RESOLUTION_DESCRIPTION  \\\n",
       "0                                                NaN   \n",
       "1  The customer should pay TF + all due amounts i...   \n",
       "2  the line is active now & linked & getting the ...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                           CASE_DESC               OPEN_GR  \\\n",
       "0                     إعادة برمجة من النظامby Sultan                   NaN   \n",
       "1      عدم التصفح وسوء الخدمه والرجاء اتخاذ قرار ...  System Administrator   \n",
       "2     Activation date Sep 22 2022  لم يتم اضافة ا...                   NaN   \n",
       "3                                               GAIA                   NaN   \n",
       "4                                        Interrupted                   NaN   \n",
       "\n",
       "  Unnamed: 22 Unnamed: 23  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd621968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276292, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60deb1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OFFER_NAME                 12430\n",
       "CUSTOMER_TYPE                  4\n",
       "COMPLAINT_TYPE                 1\n",
       "PRODUCT                        0\n",
       "CASE_LEVEL_1                   5\n",
       "CASE_LEVEL_2                   6\n",
       "CASE_LEVEL_3                   6\n",
       "CUSTOMER_GROUP             12228\n",
       "CURRENT_STATUS                 0\n",
       "ESCALATION_FLAG                0\n",
       "CASE_ID                        0\n",
       "ESCALATED_GROUP           189317\n",
       "OPEN_DATE                      0\n",
       "CLOSE_DATE                  2287\n",
       "CLOSE_GROUP               136362\n",
       "AGE_BRACKET                 2287\n",
       "ACTUAL_COMPLAINT               0\n",
       "CALLBACK_MECHANISM        192986\n",
       "RESOLUTION                192897\n",
       "RESOLUTION_DESCRIPTION    192957\n",
       "CASE_DESC                      0\n",
       "OPEN_GR                   135114\n",
       "Unnamed: 22               276268\n",
       "Unnamed: 23               276265\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab486689",
   "metadata": {},
   "source": [
    "# Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8f998",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede5cdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3da0e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import langid\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9b9f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tashaphyne in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: pyarabic in c:\\users\\user\\anaconda3\\lib\\site-packages (from tashaphyne) (0.6.15)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyarabic->tashaphyne) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tashaphyne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3674b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tashaphyne.stemming import ArabicLightStemmer\n",
    "\n",
    "def preprocess_arabic_text(text):\n",
    "    # Remove diacritics\n",
    "    text = remove_diacritics(text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = ArabicLightStemmer()\n",
    "    words = [stemmer.light_stem(word) for word in words]\n",
    "    \n",
    "    # Join the processed words back into a string\n",
    "    processed_text = ' '.join(words)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(arabic_diacritics, '', str(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33418606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import langid\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tashaphyne.stemming import ArabicLightStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "stop_words_english = set(stopwords.words('english'))\n",
    "\n",
    "stop_words_arabic = set(stopwords.words('arabic'))\n",
    "\n",
    "def preprocess_text(text, language):\n",
    "    if language == 'en':\n",
    "        # English pre-processing\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens if re.match(r'\\w', token)]\n",
    "        tokens = [token for token in tokens if token not in stop_words_english]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    elif language == 'ar':\n",
    "        # Arabic pre-processing\n",
    "        text = remove_diacritics(text)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        words = word_tokenize(text)\n",
    "        words = [word for word in words if word.lower() not in stop_words_arabic]\n",
    "        stemmer = ArabicLightStemmer()\n",
    "        words = [stemmer.light_stem(word) for word in words]\n",
    "        tokens = words\n",
    "    else:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    processed_text = ' '.join(tokens)\n",
    "    return processed_text\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(arabic_diacritics, '', str(text))\n",
    "    return text\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['CASE_DESC']\n",
    "    lang, _ = langid.classify(text)\n",
    "    processed_text = preprocess_text(text, lang)\n",
    "    df.at[index, 'preprocessed_text'] = processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2094fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0eadeb",
   "metadata": {},
   "source": [
    "## Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2e00ee6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: game\n",
      "Top 5 most similar original documents:\n",
      "                                   Original Document  Cosine Similarity\n",
      "0                                          from game           0.900524\n",
      "1                             game high ping solved            0.652722\n",
      "2  NA GOOD SPEED TEST    12.8 - 8  FROM 24  ( GAM...           0.556876\n",
      "3  kindly remove all customer service as premium ...           0.514515\n",
      "4           NAF GOOD SOLVEDPUBG GAME --EUROPE SERVER           0.446179\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "user_query = input(\"Enter your query: \")\n",
    "\n",
    "preprocessed_query = preprocess_text(user_query, langid.classify(user_query)[0])\n",
    "\n",
    "combined_text = df['CASE_DESC'].append(pd.Series([user_query]))\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_text)\n",
    "\n",
    "# Calculate cosine similarity between the user query and the documents\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "\n",
    "# Get the indices of the top 5 most similar documents\n",
    "most_similar_indices = np.argsort(cosine_similarities[0])[:-6:-1]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Original Document': [df.loc[index, 'CASE_DESC'] for index in most_similar_indices],\n",
    "    'Cosine Similarity': [cosine_similarities[0][index] for index in most_similar_indices]\n",
    "})\n",
    "\n",
    "print(\"Top 5 most similar original documents:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('similar_documents_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66c96af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'مشكل': defaultdict(<class 'int'>, {'انترنت': 5, 'شبك': 1, 'تغط': 2}), 'انترنت': defaultdict(<class 'int'>, {}), 'شبك': defaultdict(<class 'int'>, {'انترنت': 1}), 'تغط': defaultdict(<class 'int'>, {'انترنت': 2}), 'وجد': defaultdict(<class 'int'>, {'مشكل': 1, 'انترنت': 1})})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def count_co_occurrences(preprocessed_texts, co_occurrences_dict):\n",
    "    for text in preprocessed_texts:\n",
    "        words = text.split()\n",
    "\n",
    "        for i in range(len(words)):\n",
    "            # Check if the word is already in the dictionary\n",
    "            if words[i] not in co_occurrences_dict:\n",
    "                co_occurrences_dict[words[i]] = defaultdict(int)\n",
    "\n",
    "            for j in range(i + 1, len(words)):\n",
    "                # Check if the word is already in the inner dictionary\n",
    "                if words[j] not in co_occurrences_dict[words[i]]:\n",
    "                    co_occurrences_dict[words[i]][words[j]] = 0\n",
    "\n",
    "                co_occurrences_dict[words[i]][words[j]] += 1\n",
    "\n",
    "co_occurrences_dict = defaultdict(dict)\n",
    "\n",
    "# Extract preprocessed text column of the top 5 similar documents\n",
    "top_5_indices = most_similar_indices  \n",
    "preprocessed_texts_top_5 = df.loc[top_5_indices, 'preprocessed_text'].tolist()\n",
    "\n",
    "# Count co-occurrences\n",
    "count_co_occurrences(preprocessed_texts_top_5, co_occurrences_dict)\n",
    "\n",
    "print(co_occurrences_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
